{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI inference sript for Model3\n",
    "    1. Loading necessary data\n",
    "    2. Initializing model\n",
    "    3. Infer whole ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn as nn\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import openslide\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# without mc\n",
    "model_file = \"models/Model3_seed2.pth\"\n",
    "# with mc\n",
    "annotation_dict = pickle.load(open(\"wsis/test_set/MC_and_ROI_90.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# who-grade für Fälle laden\n",
    "\n",
    "csv_file = \"wsis/test_set/meningeome_rezidiv.csv\"\n",
    "who_grades = dict()\n",
    "with open(csv_file, newline = '')as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for idx,line in enumerate(reader):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        who_grades[line[0]] = list()\n",
    "        who_grades[line[0]].extend([int(line[1]),int(line[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten structure of annotation dict for Menigeome Erlangen\n",
    "tmp = dict()\n",
    "\n",
    "for key in annotation_dict:\n",
    "    for sub_key in annotation_dict[key]:\n",
    "        tmp[sub_key] = annotation_dict[key][sub_key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_annotation = dict()\n",
    "for key in tmp:\n",
    "    new_annotation[key] = dict()\n",
    "    new_annotation[key]['roi'] = tmp[key][1]\n",
    "    new_annotation[key]['mitotic_count'] = tmp[key][0]\n",
    "    new_annotation[key]['who_grade'] = who_grades['_'.join(key.split(' ')[0].split('_')[0:2])][0]\n",
    "\n",
    "annotation_dict = new_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mitotic Count standardisieren\n",
    "mcs = [annotation_dict[key]['mitotic_count'] for key in annotation_dict]\n",
    "# Standardisieren\n",
    "mean_mcs = 4.222873900293255\n",
    "std_mcs = 6.724372788197874\n",
    "max_mcs = 11.417737909245652\n",
    "\n",
    "mcs = [(m-mean_mcs)/std_mcs for m in mcs]\n",
    "# auf 1 normieren\n",
    "\n",
    "mcs = [m/max_mcs for m in mcs]\n",
    "for key,m in zip (annotation_dict, mcs):\n",
    "    annotation_dict[key]['mitotic_count'] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initializing Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import Model3\n",
    "\n",
    "model = Model3.RegressionModel()\n",
    "model.load_state_dict(torch.load(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Infer whole ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_batch(images,model,mcs = None):\n",
    "    device = 'cuda'\n",
    "    with torch.no_grad():\n",
    "        if model.training:\n",
    "            model.eval()\n",
    "        #images = [image.to(device) for image in batch]\n",
    "        predictions = model(images.to(device),mcs.to(device))\n",
    "        # Bildpfad\n",
    "        x1 = model.model(images.to(device))\n",
    "        x1 = nn.functional.sigmoid(model.fc3(x1))\n",
    "\n",
    "        # MC Pfad\n",
    "        x2 = nn.functional.sigmoid(model.fc1(mcs.to(device)))\n",
    "        x2 = model.fc2(x2)\n",
    "\n",
    "        return(predictions,x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def make_active_map(slide):\n",
    "    downsamples_int = [int(x) for x in slide.level_downsamples]\n",
    "    if 32 in downsamples_int:\n",
    "        ds = 32\n",
    "    elif 16 in downsamples_int:\n",
    "        ds = 16\n",
    "    else:\n",
    "        return\n",
    "    level = np.where(np.abs(np.array(slide.level_downsamples)-ds)<0.1)[0][0]\n",
    "    overview = slide.read_region(level=level, location=(0,0), size=slide.level_dimensions[level])\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(np.array(overview)[:,:,0:3],cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #otsu thresholding\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # dilate\n",
    "    dil = cv2.dilate(thresh, kernel = np.ones((7,7),np.uint8))\n",
    "\n",
    "    # erode --> yields map\n",
    "    activeMap = cv2.erode(dil, kernel = np.ones((7,7),np.uint8))\n",
    "\n",
    "    return(activeMap)\n",
    "\n",
    "def find_fullest_roi(activeMap,slide,roi_width,roi_height):\n",
    "    downsamples_int = [int(x) for x in slide.level_downsamples]\n",
    "    if 32 in downsamples_int:\n",
    "        ds = 32\n",
    "    elif 16 in downsamples_int:\n",
    "        ds = 16\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    x_length = int(np.ceil(float(roi_width)/ds))\n",
    "    y_length = int(np.ceil(float(roi_height)/ds))\n",
    "    kernel = np.ones((x_length,y_length), np.float32)        \n",
    "    tissue_map = cv2.filter2D(activeMap, -1, kernel, anchor = (0,0), borderType = cv2.BORDER_CONSTANT)\n",
    "    roi_center = np.unravel_index(tissue_map.argmax(), tissue_map.shape)\n",
    "    roi_center = [i * ds for i in roi_center]\n",
    "    return roi_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "file_list = list()\n",
    "for root,dirs,files in os.walk(\"/\",topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith('ndpi') and name in annotation_dict:\n",
    "            file_list.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/132 [00:27<14:12,  6.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7/132 [00:47<14:00,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9/132 [01:01<13:58,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 47/132 [05:15<09:21,  6.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 50/132 [05:34<08:49,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 59/132 [06:32<07:51,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 76/132 [08:24<06:09,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 86/132 [09:28<04:55,  6.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 87/132 [09:35<04:53,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 96/132 [10:35<03:54,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 99/132 [10:54<03:34,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 100/132 [11:01<03:29,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 111/132 [12:11<02:16,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 112/132 [12:18<02:08,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 118/132 [12:57<01:30,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 119/132 [13:04<01:24,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 124/132 [13:37<00:52,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [14:30<00:00,  6.59s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "path_to_wsis = \"wsis/test_set/\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize([0.8249, 0.5482, 0.7211], [0.0573, 0.0988, 0.0595])])\n",
    "\n",
    "level = 0\n",
    "predictions = dict()\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    key = file.split('/')[-1]\n",
    "    predictions[key] = dict()       \n",
    "    slide = openslide.open_slide(file)\n",
    "    if annotation_dict[key]['roi'] == [0, 0, 8284, 6213]:\n",
    "        print(\"###### MC == 0!!!######\")\n",
    "        # hier noch aktivste Region bestimmen!!!\n",
    "        activeMap = make_active_map(slide)\n",
    "        activeMap = activeMap / activeMap.max()\n",
    "        top_left = find_fullest_roi(activeMap,slide,8284,6213)\n",
    "        # top_left = (y,x) due to cv2 convention\n",
    "        annotation_dict[key]['roi'][0] = top_left[1]\n",
    "        annotation_dict[key]['roi'][1] = top_left[0]\n",
    "        annotation_dict[key]['roi'][2] = top_left[1] + annotation_dict[key]['roi'][2]\n",
    "        annotation_dict[key]['roi'][3] = top_left[0] + annotation_dict[key]['roi'][3]\n",
    "    predictions[key]['predictions'] = list()\n",
    "    predictions[key]['label'] = annotation_dict[key]['who_grade']\n",
    "    \n",
    "    bild_pfad = []\n",
    "    mc_pfad = []\n",
    "    gesamt = []\n",
    "    for x in range(annotation_dict[key]['roi'][0], annotation_dict[key]['roi'][2],(1024 * (level + 1))):\n",
    "        for y in range(annotation_dict[key]['roi'][1], annotation_dict[key]['roi'][3],(1024 * (level + 1))):\n",
    "            img = transform(Image.fromarray(np.array(slide.read_region((x,y),level,(1024,1024)))[:,:,:3]))\n",
    "            mcs = torch.tensor(annotation_dict[key]['mitotic_count'],dtype = torch.float32).reshape(-1,1)\n",
    "            # with mc\n",
    "            out,erg_bild,erg_mc = regress_batch(img.reshape([1,3,1024,1024]),model,mcs)\n",
    "            # with out mc\n",
    "            #out = regress_batch(img.reshape([1,3,1024,1024]),model)\n",
    "            gesamt.append(out.to('cpu').flatten())\n",
    "            mc_pfad.append(erg_mc.to('cpu').flatten())\n",
    "            bild_pfad.append(erg_bild.to('cpu').flatten())\n",
    "    predictions[key]['predictions'].append([gesamt,bild_pfad,mc_pfad])\n",
    "\n",
    "   \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \" \"\n",
    "\n",
    "pickle.dump(predictions,open(file,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
