{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI inference sript for Model1\n",
    "    1. Loading necessary data\n",
    "    2. Initializing model\n",
    "    3. Infer whole ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn as nn\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import WHO_Reg_MC4\n",
    "import openslide\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# without mc\n",
    "model_file = \"models/Model1_seed1.pth\"\n",
    "# with mc\n",
    "annotation_dict = pickle.load(open(\"MC_and_ROI_90.p\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# File with annotations of test slides\n",
    "csv_file = \"/.csv\"\n",
    "who_grades = dict()\n",
    "with open(csv_file, newline = '')as file:\n",
    "    reader = csv.reader(file, delimiter = ',')\n",
    "    for idx,line in enumerate(reader):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        who_grades[line[0]] = list()\n",
    "        who_grades[line[0]].extend([int(line[1]),int(line[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten structure of annotation dict for Menigeome Erlangen\n",
    "tmp = dict()\n",
    "\n",
    "for key in annotation_dict:\n",
    "    for sub_key in annotation_dict[key]:\n",
    "        tmp[sub_key] = annotation_dict[key][sub_key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_annotation = dict()\n",
    "for key in tmp:\n",
    "    new_annotation[key] = dict()\n",
    "    new_annotation[key]['roi'] = tmp[key][1]\n",
    "    new_annotation[key]['mitotic_count'] = tmp[key][0]\n",
    "    new_annotation[key]['who_grade'] = who_grades['_'.join(key.split(' ')[0].split('_')[0:2])][0]\n",
    "\n",
    "annotation_dict = new_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initializing Model1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegressionModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (9): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (fc2): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import Model1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model1.RegressionModel()\n",
    "model.load_state_dict(torch.load(model_file))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Infer whole ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regress_batch(images,model,mcs = None):\n",
    "    device = 'cuda'\n",
    "    with torch.no_grad():\n",
    "        if model.training:\n",
    "            model.eval()\n",
    "        if mcs == None:\n",
    "            predictions = model(images.to(device))\n",
    "        else:\n",
    "            predictions = model(images.to(device),mcs.to(device))\n",
    "        return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def make_active_map(slide):\n",
    "    downsamples_int = [int(x) for x in slide.level_downsamples]\n",
    "    if 32 in downsamples_int:\n",
    "        ds = 32\n",
    "    elif 16 in downsamples_int:\n",
    "        ds = 16\n",
    "    else:\n",
    "        return\n",
    "    level = np.where(np.abs(np.array(slide.level_downsamples)-ds)<0.1)[0][0]\n",
    "    overview = slide.read_region(level=level, location=(0,0), size=slide.level_dimensions[level])\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(np.array(overview)[:,:,0:3],cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #otsu thresholding\n",
    "    ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "    # dilate\n",
    "    dil = cv2.dilate(thresh, kernel = np.ones((7,7),np.uint8))\n",
    "\n",
    "    # erode --> yields map\n",
    "    activeMap = cv2.erode(dil, kernel = np.ones((7,7),np.uint8))\n",
    "\n",
    "    return(activeMap)\n",
    "\n",
    "def find_fullest_roi(activeMap,slide,roi_width,roi_height):\n",
    "    downsamples_int = [int(x) for x in slide.level_downsamples]\n",
    "    if 32 in downsamples_int:\n",
    "        ds = 32\n",
    "    elif 16 in downsamples_int:\n",
    "        ds = 16\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    x_length = int(np.ceil(float(roi_width)/ds))\n",
    "    y_length = int(np.ceil(float(roi_height)/ds))\n",
    "    kernel = np.ones((x_length,y_length), np.float32)        \n",
    "    tissue_map = cv2.filter2D(activeMap, -1, kernel, anchor = (0,0), borderType = cv2.BORDER_CONSTANT)\n",
    "    roi_center = np.unravel_index(tissue_map.argmax(), tissue_map.shape)\n",
    "    roi_center = [i * ds for i in roi_center]\n",
    "    return roi_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "file_list = list()\n",
    "for root,dirs,files in os.walk(\"wsis/test_set/\",topdown=False):\n",
    "    for name in files:\n",
    "        if name.endswith('ndpi') and name in annotation_dict:\n",
    "            file_list.append(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/132 [00:21<11:34,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 7/132 [00:38<11:32,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 9/132 [00:50<11:51,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 47/132 [04:30<07:57,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 50/132 [04:46<07:37,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 59/132 [05:35<06:33,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 76/132 [07:10<05:22,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 86/132 [08:06<04:19,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 87/132 [08:12<04:18,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 96/132 [09:03<03:18,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 99/132 [09:19<03:04,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 100/132 [09:25<02:59,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 111/132 [10:26<01:56,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▍ | 112/132 [10:31<01:50,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 118/132 [11:05<01:18,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████ | 119/132 [11:11<01:12,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 124/132 [11:39<00:43,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### MC == 0!!!######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [12:23<00:00,  5.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "path_to_wsis = \"wsis/test_set/\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),transforms.Normalize([0.8249, 0.5482, 0.7211], [0.0573, 0.0988, 0.0595])])\n",
    "\n",
    "level = 0\n",
    "predictions = dict()\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "for file in tqdm(file_list):\n",
    "    key = file.split('/')[-1]\n",
    "    predictions[key] = dict()       \n",
    "    slide = openslide.open_slide(file)\n",
    "    if annotation_dict[key]['roi'] == [0, 0, 8284, 6213]:\n",
    "        print(\"###### MC == 0!!!######\")\n",
    "        # hier noch aktivste Region bestimmen!!!\n",
    "        activeMap = make_active_map(slide)\n",
    "        activeMap = activeMap / activeMap.max()\n",
    "        top_left = find_fullest_roi(activeMap,slide,8284,6213)\n",
    "        # top_left = (y,x) due to cv2 convention\n",
    "        annotation_dict[key]['roi'][0] = top_left[1]\n",
    "        annotation_dict[key]['roi'][1] = top_left[0]\n",
    "        annotation_dict[key]['roi'][2] = top_left[1] + annotation_dict[key]['roi'][2]\n",
    "        annotation_dict[key]['roi'][3] = top_left[0] + annotation_dict[key]['roi'][3]\n",
    "    predictions[key]['predictions'] = list()\n",
    "    predictions[key]['label'] = annotation_dict[key]['who_grade']\n",
    "    for x in range(annotation_dict[key]['roi'][0], annotation_dict[key]['roi'][2],(1024 * (level + 1))):\n",
    "        for y in range(annotation_dict[key]['roi'][1], annotation_dict[key]['roi'][3],(1024 * (level + 1))):\n",
    "            img = transform(Image.fromarray(np.array(slide.read_region((x,y),level,(1024,1024)))[:,:,:3]))\n",
    "            mcs = torch.tensor(annotation_dict[key]['mitotic_count'],dtype = torch.float32).reshape(-1,1)\n",
    "            # with out mc\n",
    "            out = regress_batch(img.reshape([1,3,1024,1024]),model)\n",
    "            predictions[key]['predictions'].append(out.to('cpu').flatten())\n",
    "\n",
    "   \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"\"\n",
    "\n",
    "pickle.dump(predictions,open(file,\"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
